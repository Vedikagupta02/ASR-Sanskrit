#  Sanskrit Speech Recognition  
### Character-Level ASR using CNNâ€“BiLSTM + CTCâ€“Attention Hybrid Model  

This project implements an **end-to-end Automatic Speech Recognition (ASR)** system for **Sanskrit**, a low-resource and morphologically rich language.  
The model combines **Convolutional** and **Bidirectional LSTM** layers with a **hybrid CTC + Attention** decoding approach for robust alignment and contextual understanding.

---

##  Overview  
- **Architecture:** CNN + BiLSTM Encoder with CTC + Attention Decoder  
- **Features:** 240-dim log-Mel spectrograms (with delta + delta-delta)  
- **Augmentation:** SpecAugment (time & frequency masking)  
- **Loss Function:** Weighted combination of CTC and Cross-Entropy  
- **Dataset:** 3,600+ aligned Sanskrit audioâ€“text pairs  
- **Metrics:** Word Error Rate (WER), Character Error Rate (CER)

---

##  Model Highlights  
| Component | Description |
|------------|-------------|
| **Encoder** | 1D CNN frontend + 2-layer BiLSTM |
| **Decoder** | Attention-based LSTM |
| **Loss** | Hybrid (Î±Â·CTC + (1âˆ’Î±)Â·CE) |
| **Optimization** | AdamW + gradient clipping + mixed precision |
| **Framework** | PyTorch (GPU-optimized) |

---

##  Results  
| Metric | Score |
|---------|--------|
| **Word Error Rate (WER)** | **0.69** |
| **Character Error Rate (CER)** | **0.155** |

> Achieved strong recognition accuracy on a **low-resource Sanskrit dataset** with limited speaker diversity.

---

##  Key Features  
âœ… End-to-end **CTC + Attention** hybrid training  
âœ… **Character-level decoding** for better generalization  
âœ… **SpecAugment** for noise and time variation robustness  
âœ… **Greedy decoding** for fast inference  
âœ… Extensible to **beam search + language model (KenLM)**  

---

## ðŸ“‚ Directory Structure  
